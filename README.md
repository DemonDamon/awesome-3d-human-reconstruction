# nerf or pifu
* StereoPIFu: Depth Aware Clothed Human Digitization via Stereo Vision
[paper](https://arxiv.org/pdf/2104.05289.pdf)
* Learning Implicit 3D Representations of Dressed Humans from Sparse Views
[paper](https://arxiv.org/pdf/2104.08013v1.pdf)
* Animatable Neural Radiance Fields for Human Body Modeling
[paper](https://arxiv.org/pdf/2105.02872.pdf)
* PaMIR: Parametric Model-Conditioned Implicit Representation for Image-based Human Reconstruction
[paper](https://arxiv.org/pdf/2007.03858.pdf)
[code](https://github.com/ZhengZerong/PaMIR)
* Neural Actor: Neural Free-view Synthesis of Human Actors with Pose Control
[paper&code](http://gvv.mpi-inf.mpg.de/projects/NeuralActor/)
* MoCo-Flow: Neural Motion Consensus Flow for Dynamic Humans in Stationary Monocular Cameras
[paper](https://arxiv.org/pdf/2106.04477v1.pdf)
* DoubleField: Bridging the Neural Surface and Radiance Fields for High-fidelity Human Rendering
[paper](https://arxiv.org/pdf/2106.03798.pdf)
* Bridge the Gap Between Model-based and Model-free Human Reconstruction
[paper](https://arxiv.org/pdf/2106.06415v1.pdf)
* MetaAvatar: Learning Animatable Clothed Human Models from Few Depth Images
[paper](https://arxiv.org/pdf/2106.11944v1.pdf)
* Animatable Neural Radiance Fields from Monocular RGB Video
[paper](https://arxiv.org/pdf/2106.13629v1.pdf)
* Few-shot Neural Human Performance Rendering from Sparse RGBD Videos
[paper](https://arxiv.org/pdf/2107.06505v1.pdf)
* Relightable Neural Video Portrait
[paper](https://arxiv.org/pdf/2107.14735v1.pdf)
* FLAME-in-NeRF : Neural control of Radiance Fields for Free View Face Animation
[paper](https://arxiv.org/pdf/2108.04913v1.pdf)
* ARCH++: Animation-Ready Clothed Human Reconstruction Revisited
[paper](https://arxiv.org/pdf/2108.07845.pdf)
* Neural-GIF: Neural Generalized Implicit Functions for Animating People in Clothing
[paper](https://virtualhumans.mpi-inf.mpg.de/neuralgif/)
* Neural Human Performer: Learning Generalizable Radiance Fields for Human Performance Rendering
[paper](https://arxiv.org/pdf/2109.07448v1.pdf)
[code](https://youngjoongunc.github.io/nhp/)
* Topologically Consistent Multi-View Face Inference Using Volumetric Sampling
[paper](https://arxiv.org/pdf/2110.02948.pdf)
* Creating and Reenacting Controllable 3D Humans with Differentiable Rendering
[paper](https://arxiv.org/pdf/2110.11746v1.pdf)
* H-NeRF: Neural Radiance Fields for Rendering and Temporal Reconstruction of Humans in Motion
[paper](https://arxiv.org/pdf/2110.13746v1.pdf)

# 3D human whole body
* Collaborative Regression of Expressive Bodies using Moderation
[paper&code](https://pixie.is.tue.mpg.de/)
* Monocular Real-time Full Body Capture with Inter-part Correlations
[paper&code](https://calciferzh.github.io/publications/zhou2021monocular)
* Monocular Real-time Hand Shape and Motion Capture using Multi-modal Data
[paper&code](https://calciferzh.github.io/publications/zhou2020monocular)
* Real-time RGBD-based Extended Body Pose Estimation
[paper](https://arxiv.org/pdf/2103.03663.pdf)
[code](https://github.com/rmbashirov/rgbd-kinect-pose)
* Detailed Avatar Recovery from Single Image
[paper](https://arxiv.org/pdf/2108.02931v1.pdf)
* Lightweight Multi-person Total Motion Capture Using Sparse Multi-view Cameras
[paper](https://arxiv.org/pdf/2108.10378v1.pdf)

# 3D human reconstruction
* Monocular Expressive Body Regression through Body-Driven Attention
[paper](https://arxiv.org/abs/2008.09062)
[code](https://github.com/vchoutas/expose)
* FrankMocap: Fast Monocular 3D Hand and Body Motion Capture by Regression and Integration
[paper](https://arxiv.org/pdf/2008.08324.pdf)
[code](https://github.com/facebookresearch/frankmocap)
* Pose2Mesh: Graph Convolutional Network for 3D Human Pose and Mesh Recovery from a 2D Human Pose
[paper](https://arxiv.org/abs/2008.09047)
[code](https://github.com/hongsukchoi/Pose2Mesh_RELEASE)
* Monocular Real-Time Volumetric Performance Capture
[paper](https://arxiv.org/abs/2007.13988)
[code](https://github.com/Project-Splinter/MonoPort)
* Full-Body Awareness from Partial Observations
[paper](https://arxiv.org/abs/2008.06046)
[code](https://github.com/crockwell/partial_humans)
* CenterHMR: a Bottom-up Single-shot Method for Multi-person 3D Mesh Recovery from a Single Image
[paper](https://arxiv.org/pdf/2008.12272.pdf)
[code](https://github.com/Arthur151/CenterHMR)
* Reconstructing NBA players
[paper](https://arxiv.org/pdf/2007.13303.pdf)
[code](https://github.com/luyangzhu/NBA-Players)
* Going beyond Free Viewpoint: Creating Animatable Volumetric Video of Human Performances
[paper](https://arxiv.org/abs/2009.00922)
* Synthetic Training for Accurate 3D Human Pose and Shape Estimation in the Wild
[paper](https://arxiv.org/pdf/2009.10013.pdf)
[code](https://github.com/akashsengupta1997/STRAPS-3DHumanShapePose)
* MonoClothCap: Towards Temporally Coherent Clothing Capture from Monocular RGB Video
[paper](https://arxiv.org/pdf/2009.10711.pdf)
* Multi-View Consistency Loss for Improved Single-Image 3D Reconstruction of Clothed People
[paper](https://arxiv.org/abs/2009.14162)
[code](https://akincaliskan3d.github.io/MV3DH/)
* Synthetic Training for Monocular Human Mesh Recovery
[paper](https://arxiv.org/abs/2010.14036)
* Pose2Pose: 3D Positional Pose-Guided 3D Rotational Pose Prediction for Expressive 3D Human Pose and Mesh Estimation
[paper](https://arxiv.org/pdf/2011.11534.pdf)
* Deep Physics-aware Inference of Cloth Deformation for Monocular Human Performance Capture
* 4D Human Body Capture from Egocentric Video via 3D Scene Grounding
[paper](https://arxiv.org/abs/2011.13341)
* HybrIK: A Hybrid Analytical-Neural Inverse Kinematics Solution for 3D Human Pose and Shape Estimation
[paper](https://arxiv.org/pdf/2011.14672.pdf)
[code](https://github.com/Jeff-sjtu/HybrIK)
* We are More than Our Joints: Predicting how 3D Bodies Move
[paper](https://arxiv.org/pdf/2012.00619.pdf)
* SMPLy Benchmarking 3D Human Pose Estimation in the Wild
[paper](https://arxiv.org/pdf/2012.02743v1.pdf)
* Synthesizing Long-Term 3D Human Motion and Interaction in 3D
[paper](https://jiashunwang.github.io/Long-term-Motion-in-3D-Scenes/)
* Detailed 3D Human Body Reconstruction from Multi-view Images Combining Voxel Super-Resolution and Learned Implicit Representation
* A novel joint points and silhouette-based method to estimate 3D human pose and shape
* FaceDet3D: Facial Expressions with 3D Geometric Detail Prediction
[paper](https://arxiv.org/pdf/2012.07999.pdf)
* NerFACE: Dynamic Neural Radiance Fields for Monocular 4D Facial Avatar Reconstruction
[code](https://github.com/gafniguy/4D-Facial-Avatars)
* Learning Complex 3D Human Self-Contact
[paper](https://arxiv.org/pdf/2012.10366.pdf)
* Populating 3D Scenes by Learning Human-Scene Interaction
[paper](https://arxiv.org/pdf/2012.11581.pdf)
* ANR: Articulated Neural Rendering for Virtual Avatars
[paper](https://anr-avatars.github.io/)
* Human Mesh Recovery from Multiple Shots 
[paper](https://geopavlakos.github.io/multishot/)
* Lifting 2D StyleGAN for 3D-Aware Face Generation
[paper](S3: Neural Shape, Skeleton, and Skinning Fields for 3D Human Modeling)
* Capturing Detailed Deformations of Moving Human Bodies
[paper](https://arxiv.org/pdf/2102.07343.pdf)
* 3D Human Pose, Shape and Texture from Low-Resolution Images and Videos
[paper](https://arxiv.org/pdf/2103.06498v1.pdf)
* ChallenCap: Monocular 3D Capture of Challenging Human Performances using Multi-Modal References
[paper](https://arxiv.org/pdf/2103.06747v1.pdf)
* SMPLicit: Topology-aware Generative Model for Clothed People
[paper&code](http://www.iri.upc.edu/people/ecorona/smplicit/)
* Learning High Fidelity Depths of Dressed Humans by Watching Social Media Dance Videos
[paper](https://arxiv.org/pdf/2103.03319.pdf)
* NeuralHumanFVV: Real-Time Neural Volumetric Human Performance Rendering using RGB Cameras
[paper](https://arxiv.org/pdf/2103.07700v1.pdf)
* Probabilistic 3D Human Shape and Pose Estimation from Multiple Unconstrained Images in the Wild
[paper](https://arxiv.org/pdf/2103.10978v1.pdf)
* 3DCrowdNet: 2D Human Pose-Guided 3D Crowd Human Pose and Shape Estimation in the Wild
[paper](https://arxiv.org/pdf/2104.07300v1.pdf)
* SCALE: Modeling Clothed Humans with a Surface Codec of Articulated Local Elements
[paper](https://arxiv.org/pdf/2104.07660.pdf)
* Multi-person Implicit Reconstruction from a Single Image
[paper](https://arxiv.org/pdf/2104.09283v1.pdf)
* PARE: Part Attention Regressor for 3D Human Body Estimation
[paper](https://arxiv.org/pdf/2104.08527v1.pdf)
[code](https://pare.is.tue.mpg.de/)
* Temporal Consistency Loss for High Resolution Textured and Clothed 3D Human Reconstruction from Monocular Video
[paper](https://arxiv.org/pdf/2104.09259.pdf)
* Function4D: Real-time Human Volumetric Capture from Very Sparse Consumer RGBD Sensors
[paper](http://www.liuyebin.com/Function4D/Function4D.html)
* End-to-End Human Pose and Mesh Reconstruction with Transformers
[paper](https://github.com/microsoft/MeshTransformer)
* Revitalizing Optimization for 3D Human Pose and Shape Estimation: A Sparse Constrained Formulation
[paper](https://arxiv.org/pdf/2105.13965v1.pdf)
* SHARP: Shape-Aware Reconstruction of People In Loose Clothing
[paper](https://arxiv.org/pdf/2106.04778v1.pdf)
* THUNDR: Transformer-based 3D HUmaN Reconstruction with Markers
[paper](https://arxiv.org/pdf/2106.09336v1.pdf)
* Deep3DPose: Realtime Reconstruction of Arbitrarily Posed Human Bodies from Single RGB Images
[paper](https://arxiv.org/pdf/2106.11536v1.pdf)
* Learning Local Recurrent Models for Human Mesh Recovery
[paper](https://arxiv.org/pdf/2107.12847v1.pdf)
* PoseFusion2: Simultaneous Background Reconstruction and Human Shape Recovery in Real-time
[paper](https://arxiv.org/pdf/2108.00695v1.pdf)
* LASOR: Learning Accurate 3D Human Pose and Shape Via Synthetic Occlusion-Aware Data and Neural Mesh Rendering
[paper](https://arxiv.org/pdf/2108.00351v1.pdf)
* Learning Motion Priors for 4D Human Body Capture in 3D Scenes
[paper](https://arxiv.org/pdf/2108.10399v1.pdf)
[code](https://github.com/sanweiliti/LEMO)
* Probabilistic Modeling for Human Mesh Recovery
[paper&code](https://www.seas.upenn.edu/~nkolot/projects/prohmr/)
* DC-GNet: Deep Mesh Relation Capturing Graph Convolution Network for 3D Human Shape Reconstruction
[paper](https://arxiv.org/pdf/2108.12384v1.pdf)
* Encoder-decoder with Multi-level Attention for 3D Human Shape and Pose Estimation
[paper](https://arxiv.org/pdf/2109.02303v1.pdf)
[code](https://github.com/ziniuwan/maed)
* Action-Conditioned 3D Human Motion Synthesis with Transformer VAE
[code](https://github.com/Mathux/ACTOR)
* Learning to Regress Bodies from Images using Differentiable Semantic Rendering
[paper](https://arxiv.org/pdf/2110.03480v1.pdf)
* Deep Two-Stream Video Inference for Human Body Pose and Shape Estimation
[paper](https://arxiv.org/pdf/2110.11680v1.pdf)
* UltraPose: Synthesizing Dense Pose with 1 Billion Points by Human-body Decoupling 3D Model
[paper](https://arxiv.org/pdf/2110.15267v1.pdf)
* Body Size and Depth Disambiguation in Multi-Person Reconstruction from Single Images
[paper](https://arxiv.org/pdf/2111.01884v1.pdf)
[code](https://github.com/nicolasugrinovic/size_depth_disambiguation)
* Unified 3D Mesh Recovery of Humans and Animals by Learning Animal Exercise
[paper](https://arxiv.org/pdf/2111.02450v1.pdf)
* 3D Human Shape and Pose from a Single Low-Resolution Image with Self-Supervised Learning
[paper](https://arxiv.org/pdf/2007.13666.pdf)
[code](https://github.com/xuxy09/RSC-Net)
* Out-of-Domain Human Mesh Reconstruction via Bilevel Online Adaptation
[paper](https://drive.google.com/file/d/1b6e3rMrVn_xNhM-MitqpLtulARdl4M9F/view?usp=sharing)
[code](https://www.google.com/url?q=https%3A%2F%2Fgithub.com%2Fsyguan96%2FDynaBOA&sa=D&sntz=1&usg=AFQjCNHYmgSyYqdKGYNp7W-bAO2MrHfp1w)
* Monocular Human Shape and Pose with Dense Mesh-borne Local Image Features
[paper](https://arxiv.org/pdf/2111.05319v1.pdf)

# 3D human hand
* Active Learning for Bayesian 3D Hand Pose Estimation
[paper](https://arxiv.org/pdf/2010.00694.pdf)
[code](https://github.com/razvancaramalau/al_bhpe)
* Multi-View Consistency Loss for Improved Single-Image 3D Reconstruction of Clothed People
[paper](https://akincaliskan3d.github.io/MV3DH//resources/ACCV_Cam_Ready_Multi_View_3D_Human.pdf)
[code](https://github.com/akcalakcal/Multi_View_Consistent_Single_Image_3D_Human_Reconstruction)
* EventHands: Real-Time Neural 3D Hand Reconstruction from an Event Stream
* Monocular Real-time Full Body Capture with Inter-part Correlations
* Im2Mesh GAN: Accurate 3D Hand Mesh Recovery from a Single RGB Image
* HandTailor: Towards High-Precision Monocular 3D Hand Recovery
[paper](https://arxiv.org/pdf/2102.09244v1.pdf)
[code](https://github.com/LyuJ1998/HandTailor)
* Camera-Space Hand Mesh Recovery via Semantic Aggregation and Adaptive 2D-1D Registration
[paper](https://arxiv.org/pdf/2103.02845v1.pdf)
[code](https://github.com/SeanChenxy/HandMesh)
* Model-based 3D Hand Reconstruction via Self-Supervised Learning
[paper](https://arxiv.org/pdf/2103.11703v1.pdf)
[code](https://github.com/TerenceCYJ/S2HAND)
* Action-Conditioned 3D Human Motion Synthesis with Transformer VAE
[paper](https://arxiv.org/pdf/2104.05670.pdf)
* Semi-Supervised 3D Hand-Object Poses Estimation with Interactions in Time
[paper](https://arxiv.org/pdf/2106.05266v1.pdf)
* RGB2Hands: Real-Time Tracking of 3D Hand Interactions from Monocular RGB Video
[paper](https://arxiv.org/pdf/2106.11589v1.pdf)
* ArtiBoost: Boosting Articulated 3D Hand-Object Pose Estimation via Online Exploration and Synthesis
[paper](https://arxiv.org/pdf/2109.05488v1.pdf)
[code](https://github.com/MVIG-SJTU/ArtiBoost)
* Monocular 3D Reconstruction of Interacting Hands via Collision-Aware Factorized Refinements
[paper](https://arxiv.org/pdf/2111.00763v1.pdf)
[code](https://penincillin.github.io/ihmr_3dv2021)
* Dynamic Iterative Refinement for Efficient 3D Hand Pose Estimation
[paper](https://arxiv.org/pdf/2111.06500v1.pdf)

# 3d human face
* High-Fidelity 3D Digital Human Creation from RGB-D Selfies
[paper](https://arxiv.org/pdf/2010.05562.pdf)
[code](https://github.com/tencent-ailab/hifi3dface)
* StyleUV: Diverse and High-quality UV Map Generative Model
[paper](https://arxiv.org/pdf/2011.12893.pdf)
* i3DMM: Deep Implicit 3D Morphable Model of Human Heads
[paper](https://arxiv.org/pdf/2011.14143v1.pdf)
* Relightable 3D Head Portraits from a Smartphone Video
[paper](https://arxiv.org/pdf/2012.09963.pdf)
* Learning Compositional Radiance Fields of Dynamic Human Heads
[paper](https://arxiv.org/pdf/2012.09955.pdf)
* SIDER : Single-Image Neural Optimization for Facial Geometric Detail Recovery
[paper](https://arxiv.org/pdf/2108.05465v1.pdf)
* Synergy between 3DMM and 3D Landmarks for Accurate 3D Facial Geometry
[paper](https://arxiv.org/pdf/2110.09772.pdf)
[code](https://github.com/choyingw/SynergyNet)


# 3d human head
* Pixel Codec Avatars
[paper](https://arxiv.org/pdf/2104.04638.pdf)
* H3D-Net: Few-Shot High-Fidelity 3D Head Reconstruction
[paper](https://arxiv.org/pdf/2107.12512v1.pdf)

# texture 
* Spatiotemporal Texture Reconstruction for Dynamic Objects Using a Single RGB-D Camera
[paper](https://arxiv.org/pdf/2108.09007v1.pdf)
* Semi-supervised Synthesis of High-Resolution Editable Textures for 3D Humans
[paper](https://openaccess.thecvf.com/content/CVPR2021/papers/Chaudhuri_Semi-Supervised_Synthesis_of_High-Resolution_Editable_Textures_for_3D_Humans_CVPR_2021_paper.pdf)

# parametric model
* STAR: Sparse Trained Articulated Human Body Regressor
[paper](https://arxiv.org/abs/2008.08535)
[code](https://github.com/ahmedosman/STAR)

# skin
* HeterSkinNet: A Heterogeneous Network for Skin Weights Prediction
[paper](https://arxiv.org/pdf/2103.10602.pdf)

# pose estimation
* CanonPose: Self-Supervised Monocular 3D Human Pose Estimation in the Wild
[paper](https://arxiv.org/pdf/2011.14679.pdf)
* Active Learning for Bayesian 3D Hand Pose Estimation
[paper](https://arxiv.org/pdf/2010.00694v2.pdf)
[code](https://github.com/razvancaramalau/al_bhpe)
* A-NeRF: Surface-free Human 3D Pose Refinement via Neural Rendering
* HandsFormer: Keypoint Transformer for Monocular 3D Pose Estimation of Hands and Object in Interaction
[paper](https://arxiv.org/pdf/2104.14639v1.pdf)
* HuMoR: 3D Human Motion Model for Robust Pose Estimation
[paper](https://geometry.stanford.edu/projects/humor/)
* Multi-Person Extreme Motion Prediction with Cross-Interaction Attention
[paper](https://arxiv.org/abs/2105.08825)
* VoxelTrack: Multi-Person 3D Human Pose Estimation and Tracking in the Wild
[paper](https://arxiv.org/pdf/2108.02452v1.pdf)
* Gravity-Aware Monocular 3D Human-Object Reconstruction
[paper&code](http://4dqv.mpi-inf.mpg.de/GraviCap/)
* DensePose 3D: Lifting Canonical Surface Maps of Articulated Objects to the Third Dimension
[paper](https://arxiv.org/pdf/2109.00033v1.pdf)
* Graph-Based 3D Multi-Person Pose Estimation Using Multi-View Images
[paper](https://arxiv.org/pdf/2109.05885v1.pdf)
* Learning Dynamical Human-Joint Affinity for 3D Pose Estimation in Videos
[paper](https://arxiv.org/pdf/2109.07353v1.pdf)
* Physics-based Human Motion Estimation and Synthesis from Videos
[paper](https://arxiv.org/pdf/2109.09913.pdf)
* Real-time, low-cost multi-person 3D pose estimation
[paper]https://arxiv.org/pdf/2110.11414v1.pdf
* Direct Multi-view Multi-person 3D Human Pose Estimation
[paper](https://arxiv.org/pdf/2111.04076.pdf)
[code](https://github.com/sail-sg/mvp)

# registration
* LoopReg: Self-supervised Learning of Implicit Surface Correspondences, Pose and Shape for 3D Human Mesh Registration
[paper](https://virtualhumans.mpi-inf.mpg.de/papers/bhatnagar2020loopreg/bhatnagar2020loopreg.pdf)
[code](https://github.com/bharat-b7/LoopReg)
* Neural Deformation Graphs for Globally-consistent Non-rigid Reconstruction
[paper](https://arxiv.org/pdf/2012.01451.pdf)
* FARM: Functional Automatic Registration Method for 3D Human Bodies
[paper](https://arxiv.org/abs/1807.10517)
[code](https://github.com/riccardomarin/FARM)
* Locally Aware Piecewise Transformation Fields for 3D Human Mesh Registration
[paper](https://arxiv.org/pdf/2104.08160v1.pdf)
* Unsupervised 3D Human Mesh Recovery from Noisy Point Clouds
[paper](https://arxiv.org/pdf/2107.07539v1.pdf)

# others
* Fully Convolutional Graph Neural Networks for Parametric Virtual Try-On
[paper](https://arxiv.org/pdf/2009.04592.pdf)
* TailorNet: Predicting Clothing in 3D as a Function of Human Pose, Shape and Garment Style
[paper](https://arxiv.org/abs/2003.04583)
[code](https://github.com/chaitanya100100/TailorNet)
* 3DBooSTeR: 3D Body Shape and Texture Recovery
[paper](https://arxiv.org/pdf/2010.12670.pdf)
* Neural 3D Clothes Retargeting from a Single Image
[paper](https://arxiv.org/pdf/2102.00062v1.pdf)
* Single-image Full-body Human Relighting
[paper](https://arxiv.org/pdf/2107.07259.pdf)
* iButter: Neural Interactive Bullet Time Generator for Human Free-viewpoint Rendering
[paper](https://arxiv.org/pdf/2108.05577.pdf)
* A Riemannian Framework for Analysis of Human Body Surface
[paper](https://arxiv.org/pdf/2108.11449v1.pdf)
* The Power of Points for Modeling Humans in Clothing
[paper&code](https://qianlim.github.io/POP.html)
* Neural Human Deformation Transfer
[paper](https://arxiv.org/pdf/2109.01588v1.pdf)
* 3D Human Texture Estimation from a Single Image with Transformers
[paper](https://arxiv.org/pdf/2109.02563v1.pdf)
* Learning to Predict Diverse Human Motions from a Single Image via Mixture Density Networks
[paper](https://arxiv.org/pdf/2109.05776v1.pdf)
* ZFlow: Gated Appearance Flow-based Virtual Try-on with 3D Priors
[paper](https://arxiv.org/pdf/2109.07001v1.pdf)
* A Shading-Guided Generative Implicit Model for Shape-Accurate 3D-Aware Image Synthesis
[paper](https://arxiv.org/abs/2110.15678)
[code](https://github.com/XingangPan/ShadeGAN)

# correspondence
* HumanGPS: Geodesic PreServing Feature for Dense Human Correspondences
[paper](https://feitongt.github.io/HumanGPS/paper.pdf)

# application
* One-Shot Free-View Neural Talking-Head Synthesis for Video Conferencing
[paper](https://arxiv.org/pdf/2011.15126.pdf)
* LipSync3D: Data-Efficient Learning of Personalized 3D Talking Faces from Video using Pose and Lighting Normalization
[paper](https://arxiv.org/pdf/2106.04185v1.pdf)
* ARShoe: Real-Time Augmented Reality Shoe Try-on System on Smartphones
[paper](https://arxiv.org/pdf/2108.10515v1.pdf)
* A Neural Anthropometer Learning from Body Dimensions Computed on Human 3D Meshes
[paper](https://arxiv.org/pdf/2110.04064v1.pdf)

# human mattting
* Real-Time High-Resolution Background Matting
[code](https://github.com/PeterL1n/BackgroundMattingV2)
* Real-Time Monocular Human Depth Estimation and Segmentation on Embedded Systems
[paper](https://arxiv.org/pdf/2108.10506v1.pdf)

# mobile
* Mobile3DScanner: An Online 3D Scanner for High-quality Object Reconstruction with a Mobile Device
[paper](http://www.cad.zju.edu.cn/home/gfzhang//papers/mobile3dscanner/mobile3dscanner_ismar2021.pdf)
[project](https://zju3dv.github.io/mobile3dscanner.github.io/)

# dataset
* MAAD-Face: A Massively Annotated Attribute Dataset for Face Images
[paper](https://github.com/pterhoer/MAAD-Face)
* NTU60-X: TOWARDS SKELETON-BASED RECOGNITION OF SUBTLE HUMAN ACTIONS
[code](https://arxiv.org/pdf/2101.11529.pdf)
* K-Hairstyle: A Large-scale Korean hairstyle dataset for virtual hair editing and hairstyle classification
[homepage](https://www.arxiv-vanity.com/papers/2102.06288/)
* AGORA: Avatars in Geography Optimized for Regression Analysis
[homepage](https://agora.is.tue.mpg.de/)
* FaceScape: 3D Facial Dataset and Benchmark for Single-View 3D Face Reconstruction
[paper](https://arxiv.org/pdf/2111.01082v1.pdf)
* Simulated garment dataset for virtual try-on
[address](https://github.com/isantesteban/vto-dataset)

# labs
* max planck institute
[website](https://ps.is.tuebingen.mpg.de/publications)
* Yebin Liu
[website](http://www.liuyebin.com/)
* ZJU3DV
[github](https://github.com/zju3dv)

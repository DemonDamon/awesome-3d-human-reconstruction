# nerf or pifu
* StereoPIFu: Depth Aware Clothed Human Digitization via Stereo Vision
[paper](https://arxiv.org/pdf/2104.05289.pdf)
* Learning Implicit 3D Representations of Dressed Humans from Sparse Views
[paper](https://arxiv.org/pdf/2104.08013v1.pdf)
* Animatable Neural Radiance Fields for Human Body Modeling
[paper](https://arxiv.org/pdf/2105.02872.pdf)
* PaMIR: Parametric Model-Conditioned Implicit Representation for Image-based Human Reconstruction
[paper](https://arxiv.org/pdf/2007.03858.pdf)
[code](https://github.com/ZhengZerong/PaMIR)
* Neural Actor: Neural Free-view Synthesis of Human Actors with Pose Control
[paper&code](http://gvv.mpi-inf.mpg.de/projects/NeuralActor/)
* MoCo-Flow: Neural Motion Consensus Flow for Dynamic Humans in Stationary Monocular Cameras
[paper](https://arxiv.org/pdf/2106.04477v1.pdf)
* DoubleField: Bridging the Neural Surface and Radiance Fields for High-fidelity Human Rendering
[paper](https://arxiv.org/pdf/2106.03798.pdf)
* Bridge the Gap Between Model-based and Model-free Human Reconstruction
[paper](https://arxiv.org/pdf/2106.06415v1.pdf)
* MetaAvatar: Learning Animatable Clothed Human Models from Few Depth Images
[paper](https://arxiv.org/pdf/2106.11944v1.pdf)
* Animatable Neural Radiance Fields from Monocular RGB Video
[paper](https://arxiv.org/pdf/2106.13629v1.pdf)
* Few-shot Neural Human Performance Rendering from Sparse RGBD Videos
[paper](https://arxiv.org/pdf/2107.06505v1.pdf)

# 3D human whole body
* Collaborative Regression of Expressive Bodies using Moderation
[paper&code](https://pixie.is.tue.mpg.de/)
* Monocular Real-time Full Body Capture with Inter-part Correlations
[paper&code](https://calciferzh.github.io/publications/zhou2021monocular)
* Monocular Real-time Hand Shape and Motion Capture using Multi-modal Data
[paper&code](https://calciferzh.github.io/publications/zhou2020monocular)
* Real-time RGBD-based Extended Body Pose Estimation
[paper](https://arxiv.org/pdf/2103.03663.pdf)
[code](https://github.com/rmbashirov/rgbd-kinect-pose)

# 3D human reconstruction
* Monocular Expressive Body Regression through Body-Driven Attention
[paper](https://arxiv.org/abs/2008.09062)
[code](https://github.com/vchoutas/expose)
* FrankMocap: Fast Monocular 3D Hand and Body Motion Capture by Regression and Integration
[paper](https://arxiv.org/pdf/2008.08324.pdf)
[code](https://github.com/facebookresearch/frankmocap)
* Pose2Mesh: Graph Convolutional Network for 3D Human Pose and Mesh Recovery from a 2D Human Pose
[paper](https://arxiv.org/abs/2008.09047)
[code](https://github.com/hongsukchoi/Pose2Mesh_RELEASE)
* Monocular Real-Time Volumetric Performance Capture
[paper](https://arxiv.org/abs/2007.13988)
[code](https://github.com/Project-Splinter/MonoPort)
* Full-Body Awareness from Partial Observations
[paper](https://arxiv.org/abs/2008.06046)
[code](https://github.com/crockwell/partial_humans)
* CenterHMR: a Bottom-up Single-shot Method for Multi-person 3D Mesh Recovery from a Single Image
[paper](https://arxiv.org/pdf/2008.12272.pdf)
[code](https://github.com/Arthur151/CenterHMR)
* Reconstructing NBA players
[paper](https://arxiv.org/pdf/2007.13303.pdf)
[code](https://github.com/luyangzhu/NBA-Players)
* Going beyond Free Viewpoint: Creating Animatable Volumetric Video of Human Performances
[paper](https://arxiv.org/abs/2009.00922)
* Synthetic Training for Accurate 3D Human Pose and Shape Estimation in the Wild
[paper](https://arxiv.org/pdf/2009.10013.pdf)
[code](https://github.com/akashsengupta1997/STRAPS-3DHumanShapePose)
* MonoClothCap: Towards Temporally Coherent Clothing Capture from Monocular RGB Video
[paper](https://arxiv.org/pdf/2009.10711.pdf)
* Multi-View Consistency Loss for Improved Single-Image 3D Reconstruction of Clothed People
[paper](https://arxiv.org/abs/2009.14162)
[code](https://akincaliskan3d.github.io/MV3DH/)
* Synthetic Training for Monocular Human Mesh Recovery
[paper](https://arxiv.org/abs/2010.14036)
* Pose2Pose: 3D Positional Pose-Guided 3D Rotational Pose Prediction for Expressive 3D Human Pose and Mesh Estimation
[paper](https://arxiv.org/pdf/2011.11534.pdf)
* Deep Physics-aware Inference of Cloth Deformation for Monocular Human Performance Capture
* 4D Human Body Capture from Egocentric Video via 3D Scene Grounding
[paper](https://arxiv.org/abs/2011.13341)
* HybrIK: A Hybrid Analytical-Neural Inverse Kinematics Solution for 3D Human Pose and Shape Estimation
[paper](https://arxiv.org/pdf/2011.14672.pdf)
[code](https://github.com/Jeff-sjtu/HybrIK)
* We are More than Our Joints: Predicting how 3D Bodies Move
[paper](https://arxiv.org/pdf/2012.00619.pdf)
* SMPLy Benchmarking 3D Human Pose Estimation in the Wild
[paper](https://arxiv.org/pdf/2012.02743v1.pdf)
* Synthesizing Long-Term 3D Human Motion and Interaction in 3D
[paper](https://jiashunwang.github.io/Long-term-Motion-in-3D-Scenes/)
* Detailed 3D Human Body Reconstruction from Multi-view Images Combining Voxel Super-Resolution and Learned Implicit Representation
* A novel joint points and silhouette-based method to estimate 3D human pose and shape
* FaceDet3D: Facial Expressions with 3D Geometric Detail Prediction
[paper](https://arxiv.org/pdf/2012.07999.pdf)
* NerFACE: Dynamic Neural Radiance Fields for Monocular 4D Facial Avatar Reconstruction
[code](https://github.com/gafniguy/4D-Facial-Avatars)
* Learning Complex 3D Human Self-Contact
[paper](https://arxiv.org/pdf/2012.10366.pdf)
* Populating 3D Scenes by Learning Human-Scene Interaction
[paper](https://arxiv.org/pdf/2012.11581.pdf)
* ANR: Articulated Neural Rendering for Virtual Avatars
[paper](https://anr-avatars.github.io/)
* Human Mesh Recovery from Multiple Shots 
[paper](https://geopavlakos.github.io/multishot/)
* Lifting 2D StyleGAN for 3D-Aware Face Generation
[paper](S3: Neural Shape, Skeleton, and Skinning Fields for 3D Human Modeling)
* Capturing Detailed Deformations of Moving Human Bodies
[paper](https://arxiv.org/pdf/2102.07343.pdf)
* 3D Human Pose, Shape and Texture from Low-Resolution Images and Videos
[paper](https://arxiv.org/pdf/2103.06498v1.pdf)
* ChallenCap: Monocular 3D Capture of Challenging Human Performances using Multi-Modal References
[paper](https://arxiv.org/pdf/2103.06747v1.pdf)
* SMPLicit: Topology-aware Generative Model for Clothed People
[paper&code](http://www.iri.upc.edu/people/ecorona/smplicit/)
* Learning High Fidelity Depths of Dressed Humans by Watching Social Media Dance Videos
[paper](https://arxiv.org/pdf/2103.03319.pdf)
* NeuralHumanFVV: Real-Time Neural Volumetric Human Performance Rendering using RGB Cameras
[paper](https://arxiv.org/pdf/2103.07700v1.pdf)
* Probabilistic 3D Human Shape and Pose Estimation from Multiple Unconstrained Images in the Wild
[paper](https://arxiv.org/pdf/2103.10978v1.pdf)
* 3DCrowdNet: 2D Human Pose-Guided 3D Crowd Human Pose and Shape Estimation in the Wild
[paper](https://arxiv.org/pdf/2104.07300v1.pdf)
* SCALE: Modeling Clothed Humans with a Surface Codec of Articulated Local Elements
[paper](https://arxiv.org/pdf/2104.07660.pdf)
* Multi-person Implicit Reconstruction from a Single Image
[paper](https://arxiv.org/pdf/2104.09283v1.pdf)
* PARE: Part Attention Regressor for 3D Human Body Estimation
[paper](https://arxiv.org/pdf/2104.08527v1.pdf)
[code](https://pare.is.tue.mpg.de/)
* Temporal Consistency Loss for High Resolution Textured and Clothed 3D Human Reconstruction from Monocular Video
[paper](https://arxiv.org/pdf/2104.09259.pdf)
* Function4D: Real-time Human Volumetric Capture from Very Sparse Consumer RGBD Sensors
[paper](http://www.liuyebin.com/Function4D/Function4D.html)
* End-to-End Human Pose and Mesh Reconstruction with Transformers
[paper](https://github.com/microsoft/MeshTransformer)
* Revitalizing Optimization for 3D Human Pose and Shape Estimation: A Sparse Constrained Formulation
[paper](https://arxiv.org/pdf/2105.13965v1.pdf)
* SHARP: Shape-Aware Reconstruction of People In Loose Clothing
[paper](https://arxiv.org/pdf/2106.04778v1.pdf)
* THUNDR: Transformer-based 3D HUmaN Reconstruction with Markers
[paper](https://arxiv.org/pdf/2106.09336v1.pdf)
* Deep3DPose: Realtime Reconstruction of Arbitrarily Posed Human Bodies from Single RGB Images
[paper](https://arxiv.org/pdf/2106.11536v1.pdf)
* Learning Local Recurrent Models for Human Mesh Recovery
[paper](https://arxiv.org/pdf/2107.12847v1.pdf)

# 3D human hand
* Active Learning for Bayesian 3D Hand Pose Estimation
[paper](https://arxiv.org/pdf/2010.00694.pdf)
[code](https://github.com/razvancaramalau/al_bhpe)
* Multi-View Consistency Loss for Improved Single-Image 3D Reconstruction of Clothed People
[paper](https://akincaliskan3d.github.io/MV3DH//resources/ACCV_Cam_Ready_Multi_View_3D_Human.pdf)
[code](https://github.com/akcalakcal/Multi_View_Consistent_Single_Image_3D_Human_Reconstruction)
* EventHands: Real-Time Neural 3D Hand Reconstruction from an Event Stream
* Monocular Real-time Full Body Capture with Inter-part Correlations
* Im2Mesh GAN: Accurate 3D Hand Mesh Recovery from a Single RGB Image
* HandTailor: Towards High-Precision Monocular 3D Hand Recovery
[paper](https://arxiv.org/pdf/2102.09244v1.pdf)
[code](https://github.com/LyuJ1998/HandTailor)
* Camera-Space Hand Mesh Recovery via Semantic Aggregation and Adaptive 2D-1D Registration
[paper](https://arxiv.org/pdf/2103.02845v1.pdf)
[code](https://github.com/SeanChenxy/HandMesh)
* Model-based 3D Hand Reconstruction via Self-Supervised Learning
[paper](https://arxiv.org/pdf/2103.11703v1.pdf)
[code](https://github.com/TerenceCYJ/S2HAND)
* Action-Conditioned 3D Human Motion Synthesis with Transformer VAE
[paper](https://arxiv.org/pdf/2104.05670.pdf)
* Semi-Supervised 3D Hand-Object Poses Estimation with Interactions in Time
[paper](https://arxiv.org/pdf/2106.05266v1.pdf)
* RGB2Hands: Real-Time Tracking of 3D Hand Interactions from Monocular RGB Video
[paper](https://arxiv.org/pdf/2106.11589v1.pdf)

# 3d human face
* High-Fidelity 3D Digital Human Creation from RGB-D Selfies
[paper](https://arxiv.org/pdf/2010.05562.pdf)
[code](https://github.com/tencent-ailab/hifi3dface)
* StyleUV: Diverse and High-quality UV Map Generative Model
[paper](https://arxiv.org/pdf/2011.12893.pdf)
* i3DMM: Deep Implicit 3D Morphable Model of Human Heads
[paper](https://arxiv.org/pdf/2011.14143v1.pdf)
* Relightable 3D Head Portraits from a Smartphone Video
[paper](https://arxiv.org/pdf/2012.09963.pdf)
* Learning Compositional Radiance Fields of Dynamic Human Heads
[paper](https://arxiv.org/pdf/2012.09955.pdf)

# 3d human head
* Pixel Codec Avatars
[paper](https://arxiv.org/pdf/2104.04638.pdf)
* H3D-Net: Few-Shot High-Fidelity 3D Head Reconstruction
[paper](https://arxiv.org/pdf/2107.12512v1.pdf)

# parametric model
* STAR: Sparse Trained Articulated Human Body Regressor
[paper](https://arxiv.org/abs/2008.08535)
[code](https://github.com/ahmedosman/STAR)

# skin
* HeterSkinNet: A Heterogeneous Network for Skin Weights Prediction
[paper](https://arxiv.org/pdf/2103.10602.pdf)

# pose estimation
* CanonPose: Self-Supervised Monocular 3D Human Pose Estimation in the Wild
[paper](https://arxiv.org/pdf/2011.14679.pdf)
* Active Learning for Bayesian 3D Hand Pose Estimation
[paper](https://arxiv.org/pdf/2010.00694v2.pdf)
[code](https://github.com/razvancaramalau/al_bhpe)
* A-NeRF: Surface-free Human 3D Pose Refinement via Neural Rendering
* HandsFormer: Keypoint Transformer for Monocular 3D Pose Estimation of Hands and Object in Interaction
[paper](https://arxiv.org/pdf/2104.14639v1.pdf)
* HuMoR: 3D Human Motion Model for Robust Pose Estimation
[paper](https://geometry.stanford.edu/projects/humor/)
* Multi-Person Extreme Motion Prediction with Cross-Interaction Attention
[paper](https://arxiv.org/abs/2105.08825)

# registration
* LoopReg: Self-supervised Learning of Implicit Surface Correspondences, Pose and Shape for 3D Human Mesh Registration
[paper](https://virtualhumans.mpi-inf.mpg.de/papers/bhatnagar2020loopreg/bhatnagar2020loopreg.pdf)
[code](https://github.com/bharat-b7/LoopReg)
* Neural Deformation Graphs for Globally-consistent Non-rigid Reconstruction
[paper](https://arxiv.org/pdf/2012.01451.pdf)
* FARM: Functional Automatic Registration Method for 3D Human Bodies
[paper](https://arxiv.org/abs/1807.10517)
[code](https://github.com/riccardomarin/FARM)
* Locally Aware Piecewise Transformation Fields for 3D Human Mesh Registration
[paper](https://arxiv.org/pdf/2104.08160v1.pdf)
* Unsupervised 3D Human Mesh Recovery from Noisy Point Clouds
[paper](https://arxiv.org/pdf/2107.07539v1.pdf)

# others
* Fully Convolutional Graph Neural Networks for Parametric Virtual Try-On
[paper](https://arxiv.org/pdf/2009.04592.pdf)
* TailorNet: Predicting Clothing in 3D as a Function of Human Pose, Shape and Garment Style
[paper](https://arxiv.org/abs/2003.04583)
[code](https://github.com/chaitanya100100/TailorNet)
* 3DBooSTeR: 3D Body Shape and Texture Recovery
[paper](https://arxiv.org/pdf/2010.12670.pdf)
* Neural 3D Clothes Retargeting from a Single Image
[paper](https://arxiv.org/pdf/2102.00062v1.pdf)

# correspondence
* HumanGPS: Geodesic PreServing Feature for Dense Human Correspondences
[paper](https://feitongt.github.io/HumanGPS/paper.pdf)

# application
* One-Shot Free-View Neural Talking-Head Synthesis for Video Conferencing
[paper](https://arxiv.org/pdf/2011.15126.pdf)
* LipSync3D: Data-Efficient Learning of Personalized 3D Talking Faces from Video using Pose and Lighting Normalization
[paper](https://arxiv.org/pdf/2106.04185v1.pdf)

# human mattting
* Real-Time High-Resolution Background Matting
[code](https://github.com/PeterL1n/BackgroundMattingV2)

# dataset
* MAAD-Face: A Massively Annotated Attribute Dataset for Face Images
[paper](https://github.com/pterhoer/MAAD-Face)
* NTU60-X: TOWARDS SKELETON-BASED RECOGNITION OF SUBTLE HUMAN ACTIONS
[code](https://arxiv.org/pdf/2101.11529.pdf)
* K-Hairstyle: A Large-scale Korean hairstyle dataset for virtual hair editing and hairstyle classification
[homepage](https://www.arxiv-vanity.com/papers/2102.06288/)
* AGORA: Avatars in Geography Optimized for Regression Analysis
[homepage]((https://agora.is.tue.mpg.de/)

# labs
* max planck institute
[website](https://ps.is.tuebingen.mpg.de/publications)
* Yebin Liu
[website](http://www.liuyebin.com/)
